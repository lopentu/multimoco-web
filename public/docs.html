<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="GIL NTU" />
    <link rel="shortcut icon" href="./favicon.png" />

    <meta name="description" content="Multimodal corpus" />
    <meta name="keywords" content="multimoco,corpus,linguistics,multimodal" />

    <!-- Bootstrap core CSS -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="css/fontawesome.min.css" rel="stylesheet" />
    <link href="css/regular.min.css" rel="stylesheet" />
    <link href="css/solid.min.css" rel="stylesheet" />

    <link href="css/vendor-bootstrap.min.css" rel="stylesheet" />

    <link
      href="https://fonts.googleapis.com/css2?family=Work+Sans:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/earlyaccess/cwtexyen.css"
      rel="stylesheet"
    />

    <link href="css/fontawesome.min.css" rel="stylesheet" />
    <!-- Custom styles for this template -->
    <link href="css/resume.min.css" rel="stylesheet" />
  </head>

  <body id="page-top">
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light shadow fixed-top">
      <div class="container">
        <a class="navbar-brand ml-lg-5 pl-5" href="#">MultiMoco NTU</a>
        <button
          class="navbar-toggler"
          type="button"
          data-bs-toggle="collapse"
          data-bs-target="#navbarResponsive"
          aria-controls="navbarResponsive"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ms-auto">
            <li class="nav-item active">
              <a class="nav-link pl-5" href="/public/index.html#main-navbar"
                >Home</a
              >
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <nav
      class="navbar navbar-expand-lg navbar-dark fixed-top"
      id="sideNav"
      style="background-color: #131419"
    >
      <a class="navbar-brand js-scroll-trigger" href="#page-top"></a>
      <button
        class="navbar-toggler"
        type="button"
        data-toggle="collapse"
        data-target="#navbarSupportedContent"
        aria-controls="navbarSupportedContent"
        aria-expanded="false"
        aria-label="Toggle navigation"
      ></button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav align-items-lg-baseline">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#about">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#doc-search">Search</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#doc-annotation">Annotate</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#doc-project">Project Details</a>
          </li>
        </ul>
      </div>
    </nav>

    <div class="container-fluid p-0">
      <section class="resume-section p-3 p-lg-5 d-flex d-column" id="about">
        <div class="my-auto">
          <h1 class="" style="font-size: xx-large; color: #019f86">About</h1>
          <div class="subheading mb-5"></div>
          <p class="mb-5">
            MultiMoco NTU
            為臺大語言所謝舒凱老師主持之知識本體、語言處理與人文計算實驗室（LOPE）建置之多模態語料庫。本計畫借助美國加州大學洛杉磯分校（UCLA）Red
            Hen
            實驗室團隊之多模態語料分析技術，錄製數位電視公共頻道、擷取臺灣立法院議事轉播，收錄數種臺灣國家語言（華語、閩南語、客家語、原住民族語等），
            在跨文化交流的模態分析中，更廣泛且深入地探究各種語言構式。語言的形式和語意將不再受限於純文字，而是開闢了多模態表達的可能性——例如手勢、肢體動作和臉部表情，以實現人們之間相互溝通、理解之目標。
          </p>
        </div>
      </section>

      <section
        class="resume-section p-3 p-lg-5 d-flex flex-column"
        id="doc-search"
      >
        <div class="my-auto">
          <h2 class="mb-5" style="font-size: 40px; color: #019f86">
            1. Search
          </h2>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto" id="doc-search-1">
              <h3 class="mb-3">1.1 Look for a keyword</h3>
              <p class="mx-4">
                At the <span class="highlight-in-text"> Home Page </span>, we
                can enter a keyword for our subject of concern (e.g., 學校
                'school') in the search bar. <br />Then, click on the 'Search'
                button which will lead us to the
                <span class="highlight-in-text"> Result Page </span>.
              </p>
              <div class="container">
                <div class="col-10 px-0">
                  <img
                    src="./images/userguide/search-1.jpg"
                    class="img-fluid"
                    style="border:#049c84 solid 1px"
                  />
                </div>
              </div>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto" id="doc-search-2">
              <h3 class="mb-3">1.2 Browse the results</h3>
              <p class="mx-4">
                The <span class="highlight-in-text"> Result Page </span> is
                divided into four sections: (a) search bar, (b) search type, (c)
                display options, and (d) table of search resulrs. <br />The
                details of these sections are illustrated below:
              </p>
              <dl class="row mx-5 pr-xl-5">
                <dt class="col-sm-3">(a) search bar</dt>
                <dd class="col-sm-9">
                  We can search for another keyword and get another table of
                  results.
                </dd>
                <dt class="col-sm-3 text-truncate">(b) search type</dt>
                <dd class="col-sm-9">
                  We can choose to search for different type of texts (<span
                    class="highlight-in-text"
                  >
                    ASR | OCR | Blank </span
                  >) for our keyword. <br />For the example in the below
                  picture, if we search for 學校 and select ASR, <br />the
                  corpus will go through all ASR data and return the texts with
                  學校.
                </dd>
                <dt class="col-sm-3">(c) display options</dt>
                <dd class="col-sm-9 pr-xl-5">
                  After we aquire the search results, we can choose to show more
                  information happening simultaneously with the texts. That is,
                  the details of the gestures (<span class="highlight-in-text">
                    Hand movement | Palm visibility </span
                  >) and sound (<span class="highlight-in-text">
                    Overlapping </span
                  >).
                </dd>
                <dt class="col-sm-3">(d) search results</dt>
                <dd class="col-sm-9 pr-xl-5">
                  The table of search results comprises two columns (<span
                    class="highlight-in-text"
                  >
                    Info | Text </span
                  >). <br />For each matching video, the information for its
                  source channel, date, and filename. <br />Within the first
                  video, 15 texts are found with 學校 at 15 different time
                  points.
                </dd>
              </dl>
              <div class="container">
                <div class="col-10 px-0">
                  <img
                    src="./images/userguide/search-2.jpg"
                    class="img-fluid"
                    style="border:#049c84 solid 1px"
                  />
                </div>
              </div>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto" id="doc-search-3">
              <h3 class="mb-3">1.3 Check a specific result</h3>
              <p class="mx-4">
                We can take a closer look at the result texts by clicking on the
                timepoint. <br />For example, we can click on the timepoint of
                the first matching text
                <span class="highlight-in-text">[0:48]</span> <br />Then, we can
                see its corresponding image as well as the recognized phonemes,
                and the sound wave sorrounding the timepoint.
              </p>
              <div class="container">
                <div class="col-10 px-0">
                  <img
                    src="./images/userguide/search-3.jpg"
                    class="img-fluid"
                    style="border:#049c84 solid 1px"
                  />
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>

      <section
        class="resume-section p-3 p-lg-5 d-flex flex-column"
        id="doc-annotation"
      >
        <div class="my-auto">
          <h2 class="mb-5" style="font-size: 40px; color: #019f86">
            2. Annotate
          </h2>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto" id="doc-annot-1">
              <h3 class="mb-3">2.1 Select a segment</h3>
              <p class="mx-4">
                The steps for annotating on MOCO are similar to the methods used in other tools, such as Praat or ELAN.
                <br>We can specify a frame by clicking on a point <span class="highlight-in-text">(A)</span> on the waveform and then drag back to another point <span class="highlight-in-text">(B)</span>, as shown in the picture below.
              </p>
              <div class="container">
                <div class="col-10 px-0">
                  <img
                    src="./images/userguide/annotate-1.jpg"
                    class="img-fluid"
                    style="border:#049c84 solid 1px"
                  />
                </div>
              </div>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto" id="doc-annot-2">
              <h3 class="mb-3">2.2 Annotate the target segment</h3>
              <p class="mx-4">
                After we specify the segment, we can click on the yellow frame; 
                then, we can enter our annotation in the pop-up box and save it by clicking the green check mark. </p>
              <div class="container">
                <div class="col-10 px-0">
                  <img
                    src="./images/userguide/annotate-2.jpg"
                    class="img-fluid"
                    style="border:#049c84 solid 1px"
                  />
                </div>
              </div>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto" id="doc-annot-3">
              <h3 class="mb-3">2.3 Download the results and annotations</h3>
              <p class="mx-4">
                When we finish annotating, we can download the results and annotations by clicking the  <span class="highlight-in-text">Download</span>  button on the right top corner of the results.
                  <br>The table along with the specified annotations will be downloaded in the form of a <span class="highlight-in-text">.csv </span> file, which can be easily opened by spreadsheet tools or processed via programming languages.
                </p> <div class="container">
                <div class="col-10 px-0">
                  <img
                    src="./images/userguide/annotate-3.jpg"
                    class="img-fluid"
                    style="border:#049c84 solid 1px"
                  />
                </div>
              </div>
          </div>
        </div>
      </section>

      <section
        class="resume-section p-3 p-lg-5 d-flex flex-column"
        id="doc-project"
      >
        <div class="my-auto">
          <h2 class="mb-5" style="font-size: 40px; color: #019f86">
            Project Details
          </h2>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-2">Hardware Setup</h3>
              <p>
                We have combined a server with Debian Linux OS installed, a NAS
                with 4x8TB of hard drive disk mounted in RAID 5, and a
                SiliconDust HDHomeRun TV Tuner as our preliminary capture
                station. To enhance signal quality, we have an outdoor antenna
                connected via a coaxial cable. Also, both the server and the NAS
                are powered by a UPS with their network connections isolated
                from the main LAN by a router to ensure our data is secured
                physically and virtually.
              </p>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-2">Source Media</h3>
              <p>
                All 22 Taiwanese digital terrestrial television channels use the
                European-based DVB-T standard for broadcast transmission with
                their content accessible and recordable using a commercial TV
                tuner. We will mainly focus on 10 channels, including news of
                different Taiwanese languages and the consultation of the
                parliament, listed as follows:
                <span style="font-style: italic"
                  >CTV News PTS News, PTS Taigi, Hakka TV, Taiwan Indigenous TV,
                  TTV News, CTS News, Congress Channel I, Congress Channel II,
                  and FTV News.</span
                >
              </p>
              <p>
                Traditionally, the main news channels are broadcasted during
                morning, noon, and evening in Taiwan. Nevertheless, since most
                of the morning news is Mandarin-speaking, in order to meet the
                highest common factor of the four language categories we set up
                previously; plus, on account of the storage capacity, recording
                will be deployed during the evening time slots marked in bold
                above. Further, in both time slots, either one Mandarin channel
                will be chosen and take turns daily or weekly. In total, there
                will be five hours of news recorded every day, including two
                hours for Mandarin, and one hour each for Hokkien, Hakka, and
                Formosan languages. As for the congress channel, since all
                sessions are available on the Taiwan Parliament’s website with
                dedicated transcriptions in Mandarin, the data will be crawled
                directly from the Internet instead of recorded by the tuner. On
                the other hand, we are also planning to record talk shows, soap
                operas, and documentaries of the four language categories.
                Details will be provided in future communication.
              </p>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-2">Test Drive</h3>
              <p>
                We have successfully recorded the first batch of news during
                August 5-6. The resolution of the raw file captured by HDHomeRun
                is at 1080p and encoded in H.264. In this case, there would be a
                massive 2 GB per hour file size. After post-processing, the
                video is compressed at 720p and re-encoded in H.265. The
                compression process takes another hour to finish, while the
                result turns out to be the more acceptable 350MB per hour file
                size. As mentioned earlier, 5 hours of news, plus an hour of
                congress consultation –– a total of six hours recording,
                consuming approximately 2.1 GB of storage daily. Our NAS, with
                20.95 TB of free space, will be able to maintain continuous
                recording for 9,976 days, which is considerably sufficient.
              </p>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-2">Preprocessing</h3>
              <p>
                The priority of dealing with audio data of news recording is the
                speech-to-text procedure. We have been evaluating two service
                offers, one is Google Speech-to-Text API, and the other is
                Philips Dictation. The former charges USD$ 0.006/15 sec, while
                the latter is free for academic use. Both services support
                Traditional Chinese output with high confidence, while the
                latter only accepts direct input via a microphone. We are still
                considering which is more suitable. On the other hand, it is
                worth noticing that the speech-to-text service is limited to
                Mandarin only. When it comes to other Taiwanese languages, we
                are looking forward to hiring students with language-specific
                knowledge for manual transcribing.
              </p>
              <p>
                After entering the NLP pipeline, first, for the semantic and
                syntactic approach, the earlier mentioned CWN project will offer
                corresponding tools for sense tagging and construction
                extraction, respectively. Secondly, for aligning sound and text,
                tools providing semi-manual forced alignment may be suitable to
                be deployed, we are now seeking an opportunity to collaborate
                with members from the phonetics labs in our institute. Lastly,
                for establishing multimodal corpus, ELAN is a great solution for
                annotating our audiovisual recordings. Currently, we are working
                on organizing the criteria of annotating the information
                emerging from the kinetic tier, which is considered to be the
                soul of multimodality. By collaborating as the members of Red
                Hen, our goal is to provide a multilingual multimodal corpus
                with a sophisticated query system.
              </p>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto">
              <h3 class="mb-2">Goals</h3>
              <p>
                The expected goals under this research proposal would be
                two-fold—for the theoretical studies on multimodal
                communication, lexical semantics and construction grammar may
                shed unique insights in multimodal linguistic research. At the
                same time, we would be excited to join Red Hen as a collection
                site and devote ourselves to the four categories of Taiwanese
                languages data—Taiwan Mandarin, Taiwanese Hokkien, Taiwanese
                Hakka, and Formosan languages. As the study progresses, we would
                also be glad to contribute our works on Chinese NLP, multimodal
                annotations, and code tools to help make the overall process
                pipeline better.
              </p>
            </div>
          </div>
        </div>
      </section>
    </div>

    <!-- JavaScript -->
    <script src="js/vendor-jquery.min.js"></script>
    <script src="js/vendor-bootstrap.bundle.min.js"></script>
    <script src="js/vendor-jquery.easing.min.js"></script>
    <script src="js/resume.min.js"></script>
  </body>
</html>
